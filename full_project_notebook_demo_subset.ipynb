{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe6a826",
   "metadata": {},
   "source": [
    "# Demo on Stratified Subset of Original Dataset\n",
    "\n",
    "The notebook reads `data/obesity.csv`, creates a stratified subset, runs feature engineering and models on that subset, and writes all outputs to `demo_data/` and `demo_results/`. Original `data/` and `results/` are not modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7eb866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo dirs: demo_data demo_results\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "USE_SUBSET = True            # Set False to cancel (safety)\n",
    "SUBSET_SIZE = 1500            # number of samples in subset\n",
    "RANDOM_STATE = 42\n",
    "ORIG_DATA_PATH = 'data/obesity.csv'\n",
    "DEMO_DATA_DIR = 'demo_data'\n",
    "DEMO_RESULTS_DIR = 'demo_results'\n",
    "import os\n",
    "os.makedirs(DEMO_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(DEMO_RESULTS_DIR, exist_ok=True)\n",
    "print('Demo dirs:', DEMO_DATA_DIR, DEMO_RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8b7a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (2111, 17)\n",
      "Saved subset to demo_data\\obesity_subset.csv shape: (611, 17)\n"
     ]
    }
   ],
   "source": [
    "# Create stratified subset from original dataset\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "if not os.path.exists(ORIG_DATA_PATH):\n",
    "    raise FileNotFoundError(f'Original dataset not found at {ORIG_DATA_PATH}')\n",
    "orig = pd.read_csv(ORIG_DATA_PATH)\n",
    "print('Original shape:', orig.shape)\n",
    "target_col = 'NObeyesdad'\n",
    "if target_col not in orig.columns:\n",
    "    raise ValueError(f\"Target column '{target_col}' missing.\")\n",
    "if not USE_SUBSET:\n",
    "    raise RuntimeError('USE_SUBSET is False; aborting to avoid accidental full runs.')\n",
    "if SUBSET_SIZE >= len(orig):\n",
    "    subset = orig.copy()\n",
    "    print('SUBSET_SIZE >= original size; using full dataset as subset.')\n",
    "else:\n",
    "    # stratified split to get the subset\n",
    "    _, subset = train_test_split(orig, train_size=SUBSET_SIZE, stratify=orig[target_col], random_state=RANDOM_STATE)\n",
    "subset = subset.reset_index(drop=True)\n",
    "subset_path = os.path.join(DEMO_DATA_DIR, 'obesity_subset.csv')\n",
    "subset.to_csv(subset_path, index=False)\n",
    "print('Saved subset to', subset_path, 'shape:', subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb511a6",
   "metadata": {},
   "source": [
    "## Feature Engineering on subset (writes to demo_data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32da0ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed subset and saved files to demo_data\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering on the subset\n",
    "import pandas as pd, numpy as np, os, joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "subset_path = os.path.join(DEMO_DATA_DIR, 'obesity_subset.csv')\n",
    "df = pd.read_csv(subset_path)\n",
    "target_col = 'NObeyesdad'\n",
    "y = df[target_col]; X = df.drop(columns=[target_col])\n",
    "# Derived features\n",
    "if 'Height' in X.columns and 'Weight' in X.columns:\n",
    "    X = X.copy(); X['Height_m'] = X['Height']/100; X['BMI'] = X['Weight']/(X['Height_m']**2)\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# label encode target\n",
    "le = LabelEncoder(); y_train = le.fit_transform(y_train_raw); y_test = le.transform(y_test_raw)\n",
    "os.makedirs(os.path.join(DEMO_DATA_DIR,'artifacts'), exist_ok=True); joblib.dump(le, os.path.join(DEMO_DATA_DIR,'artifacts','label_encoder_target.joblib'))\n",
    "# one-hot encode\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "if len(categorical_cols)>0:\n",
    "    X_train_cat = ohe.fit_transform(X_train_raw[categorical_cols]); X_test_cat = ohe.transform(X_test_raw[categorical_cols])\n",
    "else:\n",
    "    X_train_cat = np.empty((len(X_train_raw),0)); X_test_cat = np.empty((len(X_test_raw),0))\n",
    "joblib.dump(ohe, os.path.join(DEMO_DATA_DIR,'artifacts','onehot_encoder.joblib'))\n",
    "# scale numeric\n",
    "scaler = StandardScaler()\n",
    "X_train_num = X_train_raw[numeric_cols].values if len(numeric_cols)>0 else np.empty((len(X_train_raw),0))\n",
    "X_test_num = X_test_raw[numeric_cols].values if len(numeric_cols)>0 else np.empty((len(X_test_raw),0))\n",
    "if X_train_num.size==0:\n",
    "    X_train_num_scaled = X_train_num; X_test_num_scaled = X_test_num\n",
    "else:\n",
    "    X_train_num_scaled = scaler.fit_transform(X_train_num); X_test_num_scaled = scaler.transform(X_test_num)\n",
    "joblib.dump(scaler, os.path.join(DEMO_DATA_DIR,'artifacts','scaler.joblib'))\n",
    "# combine and save\n",
    "X_train = np.hstack([X_train_num_scaled, X_train_cat]); X_test = np.hstack([X_test_num_scaled, X_test_cat])\n",
    "try:\n",
    "    ohe_cols = ohe.get_feature_names_out(categorical_cols).tolist()\n",
    "except Exception:\n",
    "    ohe_cols = []\n",
    "final_cols = numeric_cols + ohe_cols\n",
    "X_train_df = pd.DataFrame(X_train, columns=final_cols); X_test_df = pd.DataFrame(X_test, columns=final_cols)\n",
    "X_train_df.to_csv(os.path.join(DEMO_DATA_DIR,'X_train.csv'), index=False); X_test_df.to_csv(os.path.join(DEMO_DATA_DIR,'X_test.csv'), index=False)\n",
    "pd.DataFrame(y_train, columns=['target']).to_csv(os.path.join(DEMO_DATA_DIR,'y_train.csv'), index=False); pd.DataFrame(y_test, columns=['target']).to_csv(os.path.join(DEMO_DATA_DIR,'y_test.csv'), index=False)\n",
    "pd.concat([X_train_df.assign(target=y_train), X_test_df.assign(target=y_test)], ignore_index=True).to_csv(os.path.join(DEMO_DATA_DIR,'obesity_clean.csv'), index=False)\n",
    "print('Processed subset and saved files to', DEMO_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce31890",
   "metadata": {},
   "source": [
    "## Run models on subset and save outputs to demo_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b6a7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCA + SVM (demo)...\n",
      "SVM best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVM demo -> acc: 0.8943089430894309 f1_macro: 0.8877833891658776\n",
      "\n",
      "Running PCA + Logistic Regression (demo)...\n",
      "LogReg best params: {'C': 10, 'max_iter': 200, 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\saikumar\\PR PROJECT\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\saikumar\\PR PROJECT\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg demo -> acc: 0.9105691056910569 f1_macro: 0.9069803359940466\n",
      "\n",
      "Running Random Forest (demo)...\n",
      "RF best params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RF demo -> acc: 0.9512195121951219 f1_macro: 0.9485075848521226\n",
      "\n",
      "Running SelectKBest (demo) and training SVM & LogisticRegression on reduced features...\n",
      "\n",
      "Running SVM_kbest on SelectKBest features...\n",
      "SVM_kbest best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       1.00      0.82      0.90        17\n",
      "           2       1.00      1.00      1.00        20\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        19\n",
      "           5       0.87      0.76      0.81        17\n",
      "           6       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.93       123\n",
      "   macro avg       0.94      0.93      0.93       123\n",
      "weighted avg       0.94      0.93      0.93       123\n",
      "\n",
      "\n",
      "Running LogReg_kbest on SelectKBest features...\n",
      "LogReg_kbest best params: {'C': 10, 'max_iter': 200, 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\saikumar\\PR PROJECT\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\saikumar\\PR PROJECT\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       1.00      0.82      0.90        17\n",
      "           2       0.89      0.85      0.87        20\n",
      "           3       0.89      0.94      0.91        17\n",
      "           4       1.00      1.00      1.00        19\n",
      "           5       0.87      0.76      0.81        17\n",
      "           6       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.90       123\n",
      "   macro avg       0.91      0.90      0.90       123\n",
      "weighted avg       0.91      0.90      0.90       123\n",
      "\n",
      "Saved SelectKBest demo results to demo_results\\kbest_results_demo.csv\n",
      "\n",
      "Combining demo result CSVs...\n",
      "Saved combined demo results to demo_results\\final_comparison_demo.csv\n"
     ]
    }
   ],
   "source": [
    "# PCA + SVM + PCA+LR + RandomForest + SelectKBest demo (updated)\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Ensure these are defined in prior cells; otherwise set defaults\n",
    "DEMO_DATA_DIR = globals().get('DEMO_DATA_DIR', 'demo_data')\n",
    "DEMO_RESULTS_DIR = globals().get('DEMO_RESULTS_DIR', 'demo_results')\n",
    "RANDOM_STATE = globals().get('RANDOM_STATE', 42)\n",
    "\n",
    "os.makedirs(DEMO_RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(DEMO_DATA_DIR, exist_ok=True)\n",
    "\n",
    "def plot_cm(cm, classes, out_path, title):\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(classes))\n",
    "    plt.xticks(ticks, classes, rotation=45)\n",
    "    plt.yticks(ticks, classes)\n",
    "    thresh = cm.max() / 2 if cm.size else 0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 ha='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "# ---- Load processed demo data ----\n",
    "X_train = pd.read_csv(os.path.join(DEMO_DATA_DIR, 'X_train.csv'))\n",
    "X_test  = pd.read_csv(os.path.join(DEMO_DATA_DIR, 'X_test.csv'))\n",
    "y_train = pd.read_csv(os.path.join(DEMO_DATA_DIR, 'y_train.csv')).squeeze()\n",
    "y_test  = pd.read_csv(os.path.join(DEMO_DATA_DIR, 'y_test.csv')).squeeze()\n",
    "\n",
    "# ---- PCA (shared for SVM & LR) ----\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train.values)\n",
    "X_test_pca  = pca.transform(X_test.values)\n",
    "os.makedirs(DEMO_RESULTS_DIR, exist_ok=True)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.title('PCA explained variance (demo)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(DEMO_RESULTS_DIR, 'pca_explained_variance_demo.png'))\n",
    "plt.close()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)  # smaller CV for demo speed\n",
    "\n",
    "# ---------------- SVM ----------------\n",
    "print(\"Running PCA + SVM (demo)...\")\n",
    "svm = SVC()\n",
    "param_grid = {'C':[0.1,1,10], 'gamma':['scale'], 'kernel':['rbf']}\n",
    "grid = GridSearchCV(svm, param_grid, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "grid.fit(X_train_pca, y_train)\n",
    "best = grid.best_estimator_\n",
    "print('SVM best params:', grid.best_params_)\n",
    "best.fit(X_train_pca, y_train)\n",
    "y_pred = best.predict(X_test_pca)\n",
    "acc = accuracy_score(y_test, y_pred); f1m = f1_score(y_test, y_pred, average='macro'); cm = confusion_matrix(y_test, y_pred)\n",
    "print('SVM demo -> acc:', acc, 'f1_macro:', f1m)\n",
    "plot_cm(cm, sorted(map(str, np.unique(y_test))), os.path.join(DEMO_RESULTS_DIR, 'pca_svm_confusion_matrix_demo.png'), 'PCA + SVM (demo)')\n",
    "pd.DataFrame([{'model':'PCA + SVM (demo)', 'pca_components': X_train_pca.shape[1], 'accuracy':acc, 'macro_f1':f1m}]).to_csv(os.path.join(DEMO_RESULTS_DIR, 'pca_svm_results_demo.csv'), index=False)\n",
    "\n",
    "# ---------------- Logistic Regression ----------------\n",
    "print(\"\\nRunning PCA + Logistic Regression (demo)...\")\n",
    "model = LogisticRegression(multi_class='multinomial')\n",
    "param_grid = {'C':[0.1,1,10], 'max_iter':[200], 'solver':['lbfgs']}\n",
    "grid = GridSearchCV(model, param_grid, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "grid.fit(X_train_pca, y_train)\n",
    "print('LogReg best params:', grid.best_params_)\n",
    "best = grid.best_estimator_\n",
    "best.fit(X_train_pca, y_train)\n",
    "y_pred = best.predict(X_test_pca)\n",
    "acc = accuracy_score(y_test, y_pred); f1m = f1_score(y_test, y_pred, average='macro'); cm = confusion_matrix(y_test, y_pred)\n",
    "print('LogReg demo -> acc:', acc, 'f1_macro:', f1m)\n",
    "plot_cm(cm, sorted(map(str, np.unique(y_test))), os.path.join(DEMO_RESULTS_DIR, 'pca_logreg_confusion_matrix_demo.png'), 'PCA + Logistic Regression (demo)')\n",
    "pd.DataFrame([{'model':'PCA + Logistic Regression (demo)', 'pca_components': X_train_pca.shape[1], 'accuracy':acc, 'macro_f1':f1m}]).to_csv(os.path.join(DEMO_RESULTS_DIR, 'pca_logreg_results_demo.csv'), index=False)\n",
    "\n",
    "# ---------------- Random Forest ----------------\n",
    "print(\"\\nRunning Random Forest (demo)...\")\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "param_grid = {'n_estimators':[100], 'max_depth':[None], 'min_samples_split':[2]}\n",
    "grid = GridSearchCV(rf, param_grid, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "grid.fit(X_train.values, y_train)\n",
    "print('RF best params:', grid.best_params_)\n",
    "best = grid.best_estimator_\n",
    "best.fit(X_train.values, y_train)\n",
    "y_pred = best.predict(X_test.values)\n",
    "acc = accuracy_score(y_test, y_pred); f1m = f1_score(y_test, y_pred, average='macro'); cm = confusion_matrix(y_test, y_pred)\n",
    "print('RF demo -> acc:', acc, 'f1_macro:', f1m)\n",
    "# Save RF confusion matrix\n",
    "plot_cm(cm, sorted(map(str, np.unique(y_test))), os.path.join(DEMO_RESULTS_DIR, 'rf_confusion_matrix_demo.png'), 'Random Forest (demo)')\n",
    "pd.DataFrame([{'model':'Random Forest (demo)', 'accuracy':acc, 'macro_f1':f1m}]).to_csv(os.path.join(DEMO_RESULTS_DIR, 'rf_results_demo.csv'), index=False)\n",
    "\n",
    "# ---------------- SelectKBest ----------------\n",
    "print(\"\\nRunning SelectKBest (demo) and training SVM & LogisticRegression on reduced features...\")\n",
    "# Decide k\n",
    "k = min(6, X_train.shape[1]) if X_train.shape[1] > 0 else 0\n",
    "if k <= 0:\n",
    "    print(\"SelectKBest skipped (no features).\")\n",
    "else:\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_k = selector.fit_transform(X_train, y_train)\n",
    "    X_test_k  = selector.transform(X_test)\n",
    "    # Save reduced feature CSVs to demo_data for transparency\n",
    "    pd.DataFrame(X_train_k).to_csv(os.path.join(DEMO_DATA_DIR, 'X_train_selectk.csv'), index=False)\n",
    "    pd.DataFrame(X_test_k).to_csv(os.path.join(DEMO_DATA_DIR, 'X_test_selectk.csv'), index=False)\n",
    "\n",
    "    models_k = [\n",
    "        ('SVM_kbest', SVC()),\n",
    "        ('LogReg_kbest', LogisticRegression(multi_class='multinomial'))\n",
    "    ]\n",
    "    results_k = []\n",
    "    for name, mdl in models_k:\n",
    "        print(f\"\\nRunning {name} on SelectKBest features...\")\n",
    "        if isinstance(mdl, SVC):\n",
    "            param_grid = {'C':[0.1,1,10], 'gamma':['scale'], 'kernel':['rbf']}\n",
    "        else:\n",
    "            param_grid = {'C':[0.1,1,10], 'max_iter':[200], 'solver':['lbfgs']}\n",
    "\n",
    "        grid = GridSearchCV(mdl, param_grid, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "        grid.fit(X_train_k, y_train)\n",
    "        print(f\"{name} best params:\", grid.best_params_)\n",
    "        best = grid.best_estimator_\n",
    "        best.fit(X_train_k, y_train)\n",
    "        y_pred_k = best.predict(X_test_k)\n",
    "        acc_k = accuracy_score(y_test, y_pred_k)\n",
    "        f1m_k = f1_score(y_test, y_pred_k, average='macro')\n",
    "        cm_k = confusion_matrix(y_test, y_pred_k)\n",
    "        print(classification_report(y_test, y_pred_k))\n",
    "        # save confusion matrix and results\n",
    "        cm_name = os.path.join(DEMO_RESULTS_DIR, f'cm_kbest_{name}.png')\n",
    "        plot_cm(cm_k, sorted(map(str, np.unique(y_test))), cm_name, f'{name} (SelectKBest demo)')\n",
    "        results_k.append({'model': name, 'accuracy': acc_k, 'macro_f1': f1m_k})\n",
    "        # individual results csv\n",
    "        pd.DataFrame([{'model': name, 'accuracy': acc_k, 'macro_f1': f1m_k}]).to_csv(os.path.join(DEMO_RESULTS_DIR, f'kbest_results_{name}.csv'), index=False)\n",
    "\n",
    "    # combined kbest results\n",
    "    pd.DataFrame(results_k).to_csv(os.path.join(DEMO_RESULTS_DIR, 'kbest_results_demo.csv'), index=False)\n",
    "    print(\"Saved SelectKBest demo results to\", os.path.join(DEMO_RESULTS_DIR, 'kbest_results_demo.csv'))\n",
    "\n",
    "# ---------------- Combine all demo result CSVs ----------------\n",
    "print(\"\\nCombining demo result CSVs...\")\n",
    "res_files = glob.glob(os.path.join(DEMO_RESULTS_DIR, '*_results_demo.csv')) + glob.glob(os.path.join(DEMO_RESULTS_DIR, 'kbest_results_demo.csv')) + glob.glob(os.path.join(DEMO_RESULTS_DIR, 'kbest_results_*.csv'))\n",
    "# unique\n",
    "res_files = sorted(set(res_files))\n",
    "dfs = [pd.read_csv(p) for p in res_files if os.path.getsize(p) > 0]\n",
    "if dfs:\n",
    "    final = pd.concat(dfs, ignore_index=True)\n",
    "    final.to_csv(os.path.join(DEMO_RESULTS_DIR, 'final_comparison_demo.csv'), index=False)\n",
    "    print('Saved combined demo results to', os.path.join(DEMO_RESULTS_DIR, 'final_comparison_demo.csv'))\n",
    "else:\n",
    "    print('No demo result CSVs found to combine.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
