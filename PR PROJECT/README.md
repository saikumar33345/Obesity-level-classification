# Obesity Classification Using PCA, KBest & Classical ML Models Based on eating habits 
A complete machine learning pipeline for predicting obesity levels using PCA, SelectKBest, Logistic Regression, SVM, and Random Forest.

---

## Project Overview

This project builds a **full end-to-end ML classification pipeline**:

1. **Proper Feature Engineering** (NO data leakage)
2. **One-Hot Encoding** on categorical variables
3. **Standard Scaling** on numeric variables
4. **Dimensionality Reduction**
   - PCA (Logistic Regression, SVM, Random Forest)
   - SelectKBest (LR + SVM)
5. **10-Fold Cross Validation**
6. **Confusion Matrices & Results CSVs**
7. **Final comparison between all models**

---

##  Project Structure

```
PR PROJECT/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ obesity.csv
â”‚   â”œâ”€â”€ obesity_clean.csv
â”‚   â”œâ”€â”€ X_train.csv
â”‚   â”œâ”€â”€ X_test.csv
â”‚   â”œâ”€â”€ y_train.csv
â”‚   â”œâ”€â”€ y_test.csv
â”‚   â”œâ”€â”€ X_train_selectk.csv
â”‚   â”œâ”€â”€ X_test_selectk.csv
â”‚   â””â”€â”€ artifacts/
â”‚       â”œâ”€â”€ onehot_encoder.joblib
â”‚       â”œâ”€â”€ scaler.joblib
â”‚       â””â”€â”€ label_encoder_target.joblib
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ pca_svm_results.csv
â”‚   â”œâ”€â”€ pca_logreg_results.csv
â”‚   â”œâ”€â”€ pca_random_forest_results.csv
â”‚   â”œâ”€â”€ kbest_results.csv
â”‚   â”œâ”€â”€ final_comparison.csv
â”‚   â”œâ”€â”€ Confusion Matrices (PNG)
â”‚   â””â”€â”€ PCA Explained Variance Plots
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ PCA+SVM.py
â”‚   â”œâ”€â”€ PCA+LR.py
â”‚   â”œâ”€â”€ RF.py
â”‚   â”œâ”€â”€ Kbest(SVM+LR).py
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

##  How to Run the Project

### Step 1 â€” Create Virtual Environment
```sh
python -m venv venv
venv\Scripts\activate  (Windows)
source venv/bin/activate (Linux/Mac)
```

### Step 2 â€” Install Requirements
```sh
pip install -r requirements.txt
```

---

## ðŸ“Œ Step 3 â€” Run Feature Engineering (Must Run First)
```sh
python src/feature_engineering.py
```

This generates:
- X_train.csv  
- X_test.csv  
- y_train.csv  
- y_test.csv  
- one-hot encoder  
- scaler  
- label encoder  
- obesity_clean.csv  

---

## ðŸ“Œ Step 4 â€” Run ML Models

### PCA + SVM
```sh
python src/PCA+SVM.py
```

### PCA + Logistic Regression
```sh
python src/PCA+LR.py
```

### PCA + Random Forest
```sh
python src/RF.py
```

### SelectKBest (SVM + LR)
```sh
python src/"Kbest(SVM+LR).py"
```

All results are saved in:

```
results/
```

---

##  Model Performance Summary

| Model | Accuracy | Macro F1 |
|-------|----------|-----------|
| PCA + SVM | ~96% | 
| PCA + Logistic Regression | ~97% |
| Random Forest | ~98% |
| KBest + SVM | ~97% |
| KBest + LR | ~96% |

---

## âœ” Features of This Project

- NO data leakage  
- Clean train/test split  
- One-Hot Encoding only on training data  
- Scaling only on training data  
- PCA applied correctly  
- 10-fold cross validation  
- Automatic results saving  
- Confusion matrix heatmaps  
- Ranked feature importance (SelectKBest)

---

---
